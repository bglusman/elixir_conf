# Nx in Action/ Novice/ Iris / Classification

```elixir
Mix.install([
  {:axon, "~> 0.1.0"},
  {:exla, "~> 0.2.2"},
  {:nx, "~> 0.2.1"},
  {:explorer, "~> 0.2.0"},
  {:kino, "~> 0.6.2"},
  {:kino_vega_lite, "~> 0.1.1"},
  {:req, "~> 0.3.0"},
  {:scidata, "~> 0.1.9"},
  {:vega_lite, "~> 0.1.4"}
])
```

## Question

Can we prediect Iris species using a classification model?

## Load

Load the data from Scidata.

```elixir
{features, targets} = Scidata.Iris.download()
```

Normalize the data as we did in the last section.

```elixir
feature_max =
  Nx.tensor(features)
  |> Nx.reduce_max(axes: [0], keep_axes: true)

inputs =
  Enum.map(features, fn feature ->
    Nx.divide(Nx.tensor(feature), feature_max)
  end)

targets =
  Enum.map(targets, fn t ->
    Nx.tensor([t])
  end)

df = Enum.zip([inputs, targets])
```

## Train

Define the necessary values.

```elixir
epochs = 30
input_shape = {1, 4}

learning_rate = 0.001
dropout_rate = 0.1

optimizer = Axon.Optimizers.adamw(learning_rate)
loss = :mean_absolute_error
```

TODO explain

```elixir
model =
  Axon.input(input_shape, "inputs")
  |> Axon.dense(10)
  |> Axon.dropout(rate: dropout_rate)
  |> Axon.dense(1)
```

```elixir
model
|> Axon.Loop.trainer(loss, optimizer)
|> Axon.Loop.run(df, %{}, epochs: epochs)
```

```elixir
model =
  Axon.input(input_shape, "inputs")
  |> Axon.dense(25)
  |> Axon.dropout(rate: dropout_rate)
  |> Axon.dense(5)
  |> Axon.Loop.trainer(loss, optimizer)
  |> Axon.Loop.metric(:recall)
  |> Axon.Loop.run(df, %{}, epochs: epochs)
```

```elixir
# epochs = 15

model =
  Axon.input(input_shape, "inputs")
  |> Axon.dense(75)
  |> Axon.dropout(rate: dropout_rate)
  |> Axon.dense(50)
  |> Axon.dropout(rate: dropout_rate)
  |> Axon.dense(5)
  |> Axon.Loop.trainer(loss, optimizer)
  |> Axon.Loop.metric(:accuracy)
  |> Axon.Loop.run(df, %{}, epochs: epochs)
```

```elixir
model =
  Axon.input(input_shape, "input")
  |> Axon.flatten()
  |> Axon.dense(128, activation: :relu)
  |> Axon.dense(10, activation: :softmax)
```

```elixir
# trained_model =
#   model
#   |> Axon.Loop.trainer(:categorical_cross_entropy, :adam)
#   |> Axon.Loop.metric(:accuracy, "Accuracy")
#   # |> Axon.Loop.metric(:precision)
#   # |> Axon.Loop.metric(:recall)
#   |> Axon.Loop.run(df, %{}, epochs: epochs)
```

## Metrics

#### Accuracy

_How accurate is the model at making predictions on unseen data?_

The number of correct predictions relative to the total number of predictions

`(true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg)`

#### Precision

_Out of all positive predictions made by the model, what percentage are truly positive?_

The number of actual positive classes (`true_pos`) found in the dataset relative to the number of actual positive classes (`true_pos`) plus classes that were falsely identified as positive (`false_pos`).

(true_pos) / (true_pos + false_pos)

#### Recall

_Of all of the actual positive classes in the dataset, how many of them did the model recall?_

The number of actual positive classes (`true_pos`) relative to the number of actual positive classes (`true_pos`) plus classes that were falsely identified as negative (`false_neg`) â€” those misidentified as negative.

`(true_pos) / (true_pos + false_neg)`

##### Confusion Matrix

|                          | Positive (Actual) | Negative (Actual) |
| ------------------------ | ----------------- | ----------------- |
| **Positive (Predicted)** | True Positive     | False Positive    |
| **Negative (Predicted)** | True Negative     | False Negative    |

***

|                              | Truth: Yes hot dog! | Truth: No hot dog   |
| ---------------------------- | ------------------- | ------------------- |
| **Prediction: Yes hot dog!** | Hot Dog (food)      | Hot Dog (Dachshund) |
| **Prediction: No hot dog**   | Chili Dog (food)    | Pizza (food)        |

## Train

### Classification Algorithm

We will train a multiclass classification model on this dataset.

It will map the input values (`x`) to a discrete output variable (`y`) and makes predictions by categorizing data into classes based on independent variables.

#### Outcome is CATEGORICAL: predicts a discrete (finite) class label.

##### Multiclass classification (more than two outcome labels)

* Iris species prediction  
  * setosa / versicolor /virginica

<!-- livebook:{"break_markdown":true} -->

### Define the Model

1. Epochs - how many training iterations to take over the dataset
2. Learning rate - size of the optimization step at each iteration
3. Loss - measure of the distance between the prediction from the label

```elixir
epochs = 20
learning_rate = 0.001
loss = :mean_squared_error
```

### Define Loss and Optimizer

First, the deaths in the dataset.

```elixir
import Nx.Defn
```

```elixir
weights = Nx.random_normal({3, 1}, 0.0, 0.1)
bias = Nx.random_normal({1, 1}, 0.0, 0.1)
wb = {weights, bias}
```

#### Loss

The loss function measures how well a model fit the data set.The bigger the difference between the prediction and the ground truth (target or class), the higher the loss function value.

```elixir
loss =
  &Axon.Losses.binary_cross_entropy(
    &1,
    &2,
    negative_weight: 1 / nondeaths,
    positive_weight: 1 / deaths,
    reduction: :mean
  )
```

Then the optimizer.

```elixir
optimizer = Axon.Optimizers.adam(0.01)
```

### UNDER CONSTRUCITON these are bits and pieces from rough drafts; pull into the right areas

#### Train and run the model

When training, set the loss function and optimizer. When running, set the number of epochs.

##### Loss Function

The loss function measures how well a model fit the data set.The bigger the difference between the prediction and the ground truth (target or class), the higher the loss function value.

##### Optimizer

Implementations of common gradient-based optimization algorithms. Customize the Optimizer by passing in a learning rate. The learning rate is the amount the weights are updated during training. It is a hyperparameter. Use hyperparameters to fine tune your model.

##### Metric

Metrics are used to measure the performance and compare performance of models.

* Accuracy tells you how many times the model was correct overall
* Precision is how good the model is at predicting a specific category
* Recall tells you how many times the model was able to detect a specific category

##### Epochs

An epoch refers to one complete pass of the training data through the algorithm. It is  a hyperparameter. The maximum epochs to run the Axon loop for. Must be non-negative integer (default is 1).
