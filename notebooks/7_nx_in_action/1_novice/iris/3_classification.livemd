# Nx in Action/ Novice/ Iris / Classification

```elixir
Mix.install([
  {:axon, "~> 0.1.0"},
  {:exla, "~> 0.2.2"},
  {:nx, "~> 0.2.1"},
  {:explorer, "~> 0.2.0"},
  {:kino, "~> 0.6.2"},
  {:kino_vega_lite, "~> 0.1.1"},
  {:req, "~> 0.3.0"},
  {:scidata, "~> 0.1.9"},
  {:vega_lite, "~> 0.1.4"}
])
```

## The Plan

1. Define the problem
2. Pepare the data
3. Evaluate the algorithms
4. Choose the model
5. Make the predictions

## Define the problem

Can we predict Iris species?

## Prepare the data

Load the data from Scidata.

```elixir
{inputs, targets} = Scidata.Iris.download()
```

```elixir
count = Enum.count(inputs)
```

```elixir
imax =
  Nx.tensor(inputs)
  |> Nx.reduce_max(axes: [0], keep_axes: true)

inputs =
  Enum.map(inputs, fn i ->
    Nx.divide(Nx.tensor(i), imax)
  end)

targets = Enum.map(targets, &Nx.tensor([&1], type: {:s, 32}))

# shuffle to disperse the species as the dataset has them in order 0-2
# TODO add this to the previous section on data prep
# TODO notice it and solve it there too
dataset = Enum.zip(inputs, targets) |> Enum.shuffle()
```

```elixir
ratio = 0.85
split = fn d -> Enum.split(d, ceil(count * ratio)) end

{train, test} = split.(dataset)

# TODO move this to the test to test later
# test = Enum.map(test, fn {input, _target} -> input end)
```

## Evaluate the algorithms

#### Define the Model

1. Epochs - how many training iterations to take over the dataset
2. Optimzer - function used to update weights and biases (hyperparameters)
3. Loss - how best to measure **loss** (distance between prediction & target)
4. Metric (optional) - choose metric to measure model's performance
5. Learning rate (optional) - size of the optimization step at each iteration

<!-- livebook:{"break_markdown":true} -->

TODO divide the above sections into refinements of the model step by step

play with optimizer
play with loss

### Experiment with Optimziers

optimizer = :adamw

```elixir
epochs = 25
optimizer = :adam
loss = :mean_absolute_error

# the shape of our input: 1 row of 4 columns
input_shape = {1, 4}
```

To define the model, give the input shape along with a name for the input.

```elixir
input_name = "Iris Features"
model = Axon.input(input_shape, input_name)
```

Note the parameters at this point require 0 bytes of memory. That is because there are no layers to neural network. Before we add one, run the model in this state.

```elixir
model
|> Axon.Loop.trainer(loss, optimizer)
|> Axon.Loop.run(train, %{}, epochs: epochs)
```

Notice the loss rate. It stays the roughly the same each epoch. This is because we aren't doing anything to actually learn. Each layer helps the neural network learn accurate representations of the input data. Without learning, the model performs badly.

<!-- livebook:{"break_markdown":true} -->

Let's add a layer. Pipe it afer the input and provide a `unit` to specify the number of output units. We'll start with 1.

```elixir
model =
  Axon.input(input_shape, input_name)
  |> Axon.dense(1, name: "First Layer")
```

Run it with the new layer.

```elixir
model
|> Axon.Loop.trainer(loss, optimizer)
|> Axon.Loop.run(train, %{}, epochs: epochs)
```

Much improved! In this run, our loss dropped consistently from on epoch to the next.

Add another layer.

```elixir
model =
  Axon.input(input_shape, input_name)
  |> Axon.dense(5, name: "First Layer")
  |> Axon.dense(1, name: "Second Layer")
```

```elixir
model
|> Axon.Loop.trainer(loss, optimizer)
|> Axon.Loop.run(train, %{}, epochs: epochs)
```

### Metric

Metrics are used to measure the performance of models.

##### Accuracy

The number of times the model was correct overall

_How accurate is the model at making predictions on unseen data?_

`(true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg)`

##### Precision

Tells you how good the model is at prediction a specific category.

_Out of all positive predictions made by the model, what percentage are truly positive?_

The number of actual positive classes (`true_pos`) found in the dataset relative to the number of actual positive classes (`true_pos`) plus classes that were falsely identified as positive (`false_pos`).

(true_pos) / (true_pos + false_pos)

##### Recall

Tells you how many times the model was able to detect a specific category.

_Of all of the actual positive classes in the dataset, how many of them did the model recall?_

The number of actual positive classes (`true_pos`) relative to the number of actual positive classes (`true_pos`) plus classes that were falsely identified as negative (`false_neg`) â€” those misidentified as negative.

`(true_pos) / (true_pos + false_neg)`

###### Confusion Matrix

|                          | Positive (Actual) | Negative (Actual) |
| ------------------------ | ----------------- | ----------------- |
| **Positive (Predicted)** | True Positive     | False Positive    |
| **Negative (Predicted)** | True Negative     | False Negative    |

<!-- livebook:{"break_markdown":true} -->

#### Recall Metric

```elixir
model =
  Axon.input(input_shape, "inputs")
  |> Axon.dense(25)
  |> Axon.dropout(rate: dropout_rate)
  |> Axon.dense(5)
  |> Axon.Loop.trainer(loss, optimizer)
  |> Axon.Loop.metric(:recall)
  |> Axon.Loop.run(df, %{}, epochs: epochs)
```

#### Accuracy Metric

```elixir
# epochs = 15

model =
  Axon.input(input_shape, "inputs")
  |> Axon.dense(75)
  |> Axon.dropout(rate: dropout_rate)
  |> Axon.dense(50)
  |> Axon.dropout(rate: dropout_rate)
  |> Axon.dense(5)
  |> Axon.Loop.trainer(loss, optimizer)
  |> Axon.Loop.metric(:accuracy)
  |> Axon.Loop.run(df, %{}, epochs: epochs)
```

```elixir
loss = :categorical_cross_entropy

model =
  Axon.input(input_shape, "inputs")
  |> Axon.dense(128, activation: :relu)
  |> Axon.layer_norm()
  |> Axon.dropout()
  |> Axon.dense(10, activation: :softmax)
  |> Axon.Loop.trainer(loss, optimizer)
  |> Axon.Loop.run(df, %{}, epochs: epochs)
```

```elixir
loss = :categorical_cross_entropy

model =
  Axon.input(input_shape, "inputs")
  |> Axon.dense(128, activation: :relu)
  |> Axon.layer_norm()
  |> Axon.dropout(rate: dropout_rate)
  |> Axon.dense(5, activation: :softmax)
  |> Axon.Loop.trainer(loss, optimizer)
  |> Axon.Loop.metric(:accuracy)
  |> Axon.Loop.run(df, %{}, epochs: epochs)
```

HELP! TODO: need help understanding why adding softmax as the final activation function makes the accuracy so much worse?

Our problem is a multi-class classification problem. That means we want to classify irises into one of 3 classes: setosa, versicolor, or virginica.

We'll use `:softmax` as our activation function. It returns the probability of each class. It is most commonly used as an activation function for the last layer of the neural network in the case of multi-class classification.

## Advanced

TODO consider adding an advanced section
with these

#### Dropout Rate

The rate at which to randomly drop out nodes during training to 
prevent overfitting and improve generalization error.

```elixir
# dropout_rate = 0.1
```
