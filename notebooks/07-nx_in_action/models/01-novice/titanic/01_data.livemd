# Nx in Action / Novice / Data

```elixir
Mix.install([
  {:nx, "~> 0.2.1"},
  {:explorer, "~> 0.2.0"},
  {:kino, "~> 0.6.2"},
  {:kino_vega_lite, "~> 0.1.1"},
  {:vega_lite, "~> 0.1.4"}
])
```

## Question

Can we predict passangers who will survive the Titanic disaster?

## Dataset

The Titanic Distaster Dataset describes the survival status of individual passengers
on the Titanic. It does not contain information from the crew.

<span style="font-size: 14px;">
The principal source for data about Titanic passengers is the Encyclopedia Titanica. The datasets used here were begun by a variety of researchers. One of the original sources is Eaton & Haas (1994) Titanic: Triumph and Tragedy, Patrick Stephens Ltd, which includes a passenger list created by many researchers and edited by Michael A. Findlay.
</span>

![](images/titanic.png)

<!-- livebook:{"break_markdown":true} -->

### Features

* Survival `int`  (0 = No; 1 = Yes)
* Class `int` (1 = 1st; 2 = 2nd; 3 = 3rd)
* Name `string`
* Sex `string`
* Age `float`
* Sibsp `int`
* Parch `int`
* Ticket `string`
* Fare  `int`
* Cabin `string`
* Embarked `string`

<!-- livebook:{"break_markdown":true} -->

### Observations

`Age` is fractional if less than 1. If estimated, is it in the form of xx.5

`Embarked`

* C = Cherbourg
* Q = Queenstown
* S = Southampton

Family relations are defined as:

* Sibling (`SibSp`) = brother, sister, stepbrother, stepsister
* Spouse (`SibSp`) = husband, wife (mistresses and fiancÃ©s were ignored)
* Parent (`Parch`) = mother, father
* Child (`Parch`) = daughter, son, stepdaughter, stepson

## Load

With the use of Explorer, we can easily load the iris data into a dataframe.

```elixir
alias Explorer.DataFrame
alias Explorer.Series
```

```elixir
csv_train = "elixir_conf/data/titanic/train.csv"
df = DataFrame.from_csv!(csv_train)

csv_test = "elixir_conf/data/titanic/test.csv"
df_test = DataFrame.from_csv!(csv_test)
```

```elixir
DataFrame.shape(df)
```

```elixir
DataFrame.names(df)
```

## Visualize

To visualize the data, use Explorer to sample a few rows of the Dataframe with `sample/3` and print it out in a table view with `table/2`

```elixir
df
|> DataFrame.table(limit: 3)
```

```elixir
df["Survived"] |> Series.count()
```

```elixir
df["Sex"] |> Series.count()
```

```elixir
df_test["Sex"] |> Series.count()
```

### Data Analytics

<!-- livebook:{"break_markdown":true} -->

### Smart Cells

Another way to visualize the data is to use Livebook SmartCells. Set the data to the Iris dataframe and select an x-axis and y-axis.

Lets determine if our dataset is balanced. How many passengers survived?

<!-- livebook:{"attrs":{"chart_title":null,"height":750,"layers":[{"chart_type":"bar","color_field":"Survived","color_field_aggregate":null,"color_field_type":"nominal","data_variable":"df","x_field":"Sex","x_field_aggregate":null,"x_field_type":"nominal","y_field":"__count__","y_field_aggregate":null,"y_field_type":null}],"vl_alias":"Elixir.VegaLite","width":500},"kind":"Elixir.KinoVegaLite.ChartCell","livebook_object":"smart_cell"} -->

```elixir
VegaLite.new(width: 500, height: 750)
|> VegaLite.data_from_values(df, only: ["Sex", "Survived"])
|> VegaLite.mark(:bar)
|> VegaLite.encode_field(:x, "Sex", type: :nominal)
|> VegaLite.encode(:y, aggregate: :count)
|> VegaLite.encode_field(:color, "Survived", type: :nominal)
```

<!-- livebook:{"attrs":{"chart_title":null,"height":400,"layers":[{"chart_type":"bar","color_field":"Pclass","color_field_aggregate":null,"color_field_type":"quantitative","data_variable":"df","x_field":"Survived","x_field_aggregate":null,"x_field_type":"ordinal","y_field":"Fare","y_field_aggregate":null,"y_field_type":"quantitative"}],"vl_alias":"Elixir.VegaLite","width":500},"kind":"Elixir.KinoVegaLite.ChartCell","livebook_object":"smart_cell"} -->

```elixir
VegaLite.new(width: 500, height: 400)
|> VegaLite.data_from_values(df, only: ["Survived", "Fare", "Pclass"])
|> VegaLite.mark(:bar)
|> VegaLite.encode_field(:x, "Survived", type: :ordinal)
|> VegaLite.encode_field(:y, "Fare", type: :quantitative)
|> VegaLite.encode_field(:color, "Pclass", type: :quantitative)
```

## Preprocessing

Let's take a look at one of the rows.

```elixir
age_values = df["Age"]
```

Notice some of the values are `nil`. How many are `nil`?

```elixir
age_values |> Series.nil?() |> Series.to_list() |> Enum.frequencies()
```

Check the other rows, too.

```elixir
Enum.each(DataFrame.names(df), fn name ->
  cnt = df[name] |> Series.nil?() |> Series.to_list() |> Enum.frequencies()

  case cnt do
    %{false: _, true: n} -> IO.puts("#{name}: #{n}")
    _ -> nil
  end
end)
```

And the test dataset.

```elixir
Enum.each(DataFrame.names(df_test), fn name ->
  cnt = df_test[name] |> Series.nil?() |> Series.to_list() |> Enum.frequencies()

  case cnt do
    %{false: _, true: n} -> IO.puts("#{name}: #{n}")
    _ -> nil
  end
end)
```

#### What do to with Nil values

We have options for handling nil values. We can fill the nil values with other values using different strategies.

##### Strategies

* forward - replace nil with the previous value
* backward - replace nil with the next value
* max - replace nil with the series maximum
* min - replace nil with the series minimum
* mean - replace nil with the series mean

For the missing Age values we'll use the forward.

```elixir
df =
  Explorer.DataFrame.mutate(df,
    Age:
      df["Age"]
      |> Series.fill_missing(:forward)
  )

df_test =
  Explorer.DataFrame.mutate(df_test,
    Age:
      df_test["Age"]
      |> Series.fill_missing(:forward)
  )
  |> Explorer.DataFrame.mutate(
    Fare:
      df_test["Fare"]
      |> Series.fill_missing(:forward)
  )
```

### Extract

<!-- livebook:{"break_markdown":true} -->

Certain columns, like Cabin, seem unlike to influence accurancy. Extract the data we want and then Transform it. Drop Name, Ticket, Cabin, Embarked, and PassengerId.

```elixir
df = DataFrame.select(df, ["Survived", "Pclass", "Sex", "Age", "SibSp", "Parch", "Fare"])
```

Review the new shape.

```elixir
DataFrame.shape(df)
```

Do the same for the test dataset, but remember it will not contain the column for the target ("Surivived").

```elixir
DataFrame.shape(df_test)
```

```elixir
df_test = DataFrame.select(df_test, ["Pclass", "Sex", "Age", "SibSp", "Parch", "Fare"])
```

We went from a shape of `{418, 11}` to `{418, 6}`.

```elixir
DataFrame.shape(df_test)
```

## Transform

### Normalize

<!-- livebook:{"break_markdown":true} -->

Normalize the features toe values between 0 and 1. Start with our remaining `string`.

```elixir
s =
  Series.transform(df["Sex"], fn v ->
    if v == "female", do: 0, else: 1
  end)

df = Explorer.DataFrame.mutate(df, Sex: s)
```

Repeat for the test data.

```elixir
s_test =
  Series.transform(df_test["Sex"], fn v ->
    if v == "female", do: 0, else: 1
  end)

df_test = Explorer.DataFrame.mutate(df_test, Sex: s_test)
```

From the training set, create a data frame of features and another of just the target column.

```elixir
targets = DataFrame.select(df, &(&1 == "Survived"), :keep)
features = DataFrame.select(df, &(&1 == "Survived"), :drop)
```

Convert them to tensors. Then zip them together.

```elixir
to_tensor = fn df ->
  df
  |> Explorer.DataFrame.names()
  |> Enum.map(&(Explorer.Series.to_tensor(df[&1]) |> Nx.new_axis(-1)))
  |> Nx.concatenate(axis: 1)
end

targets = to_tensor.(targets)
features = to_tensor.(features)
training_set = Stream.zip(features, targets)
```

Convert the test set.

```elixir
to_tensor = fn df_test ->
  df_test
  |> Explorer.DataFrame.names()
  |> Enum.map(&(Explorer.Series.to_tensor(df_test[&1]) |> Nx.new_axis(-1)))
  |> Nx.concatenate(axis: 1)
end

testing_set = to_tensor.(df_test)
```

## Write to File

Save the normalized sets to use to train our model in the next section. Use Kino save the files.

<!-- livebook:{"break_markdown":true} -->

Using `Kino.Input`, evaluate the code block and then put the file location in the resulting input area below the code block. For example:

`elixir_conf/data/titanic/normalized/train.csv`

After you enter the input, evaluate the next code block. You should see the filname printed out.

```elixir
train_filename = Kino.Input.text("Training Filename")
```

```elixir
train_file = Kino.Input.read(train_filename)
```

Write the data to the file.

```elixir
DataFrame.to_csv(df, train_file)
```

Repeat the sames steps for the test data with a different file name:

`elixir_conf/data/titanic/normalized/test.csv`

```elixir
test_filename = Kino.Input.text("Test Filename")
```

```elixir
test_file = Kino.Input.read(test_filename)
```

```elixir
DataFrame.to_csv(df_test, test_file)
```

Now it's time to train the models.

<!-- livebook:{"break_markdown":true} -->

[<span style="float: right; color: #800080; font-weight: bold; font-family: FreeMono, monospace">next ></span>](01_train.livemd)
