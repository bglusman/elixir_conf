# Machine Learning / Introduction

```elixir
Mix.install([
  {:gibran, git: "https://github.com/abitdodgy/gibran"}
])
```

## Goal

After an introduction to machine learning we will define, train, and test a machine learning model using a publicly available dataset. We will then employ the model to make predictions. This lesson serves as an introduction fto and an overview of machine learning.

<!-- livebook:{"break_markdown":true} -->

### Introduction

Machine learning (ML) is a type of artificial intelligence (AI), and is the process by which machines improve their performance without explicit programming. Machines discover patterns, are able to make predictions, and get better over time with exposure to data. They become increasingly accurate at predicting outcomes without being explicitly programmed. Historical data is given as training input. Through training and testing, the machine learning algorithms are able to predict new, unseen output values.

#### Common uses

* classification of images
* recommendation engines
* fraud and threat detection
* business process automation

<!-- livebook:{"break_markdown":true} -->

![breeds](images/breeds.png)

<!-- livebook:{"break_markdown":true} -->

### Types of Machine Learning

Machine learning types are broken down by how an algorithm learns prediction accuracy. Growing your knowledge of ML means knowing the question you are asking and how to choose the algorithm based on the type of data you want to predict.

There are three main types of machine learning

* Supervised learning
* Unsupervised learning
* Reinforcement learning

We will cover each of the 3 types in the next section.

<!-- livebook:{"break_markdown":true} -->

### How it Works

A supervised learning system has a data flow that looks like this:

<!-- livebook:{"break_markdown":true} -->

```mermaid
graph TD;
  ML{{Supervised Machine Learning}}-->TRN([TRAINING]);
  ML-->TST[TESTING];
  TRN-->In([Input training dataset]);
  In-->LS([Learning System]);
  In---GT([Ground Truth]);
  LS-->Out([Verifiable Output]);
  Out-->M((Model));
  GT-->Out;
  TST-->UD[New, unseen input data];
  UD-->M;
  M-->P[[Prediction, a.k.a best guess]]
  
```

<!-- livebook:{"break_markdown":true} -->

Most supervised machine learning can be divided as either **Classification** or **Regression**.

The goal of ML is to make a **prediction**.

Once a prediction is made it is compared to the **Ground Truth** (the expected result).

The **Loss Function** gives a quantity to the distance between the prediction and the ground truth.

Regression algorithms typically use Mean Square Error (MSE), which determines loss as the average squared difference between the prediction and the ground truth.

CLassification algorithms typically use Cross Entropy Loss (aka softmax), which measures loss as the difference between probabilities that a model assigns to classes

<!-- livebook:{"break_markdown":true} -->

```mermaid
graph TD;
  ML([Machine Learning])-->PD([Prediction]);
  PD-->LF([Loss Function]);
  GT([Ground Truth])-->LF;
  LF-->RG([Regression]);
  LF-->CL([Classification]);
  RG-->MSE([Mean Squared Error]);
  CL-->CEL([Cross Entropy Loss]);
```

<!-- livebook:{"break_markdown":true} -->

### ML Algorithms

An algorithm is a mathematical process upon which following specific steps lead to an expected outcome. In Machine Learning, algorithms draw upon linear algebra, statistics and calculus to weigh the probability of multiple outcomes. They can be implemented in a variety of different languages.

Essentially, ML algorithms are functions with an input of data and an output of predictive models.

Examples of well-known algorithms are:

* Regression (linear, logistic, etc.)
* Classification
* Clustering
* Decision Trees
* Random Forest
* k-Nearest Neighbors
* Artificial neural networks

<!-- livebook:{"break_markdown":true} -->

![](images/decision_tree.png)

<span style="float: right; font-size: 12px;">
_Decision Tree_
</span>

<!-- livebook:{"break_markdown":true} -->

### Models

If a machine learning model is the output of an algorithm, at its most basic it is a file. The file has been trained to recognize patterns by a set of data. An algorithm is used to reason over and learn from the data. During training, the algorithm is optimized to find certain patterns in the dataset resulting in a file called a machine learning model.

It represents what's been learned from the algorithm using a training dataset, and it contains a prediction algorithm. So an algorithm like linear regression will produce a model made of a vector of coefficients with specific values. Whereas a decision tree algorithm will result in a model made of a tree of conditions with specific values.

Once trained, the model can reason over data it hasn't seen before and make predictions. If it's been trained well, it can make accurate predictions on similar but previously unseen data.

For example, machine learning models can be used for natural language processing (NLP). Those models parse and correctly recognize the intent or sentiment of combinations of words. Image recognition machine learning models can learn to recognize and discern objects.

## Model Training

Model training is the process of running a machine learning algorithm on a dataset and optimizing the algorithm to find patterns is called model training. The data set is referred to as the training data. The result is the model, a function made of rules and data structures.

<!-- livebook:{"break_markdown":true} -->

<hr style="background-color: #800080;height: 15.0px;" />

## Brain Break!

<span style="color: #800080; font-size:30px; font-weight: bold; font-family: FreeMono, monospace">
Time for some Elixir
</span>

<img src="https://static.thenounproject.com/png/1111032-200.png" alt="Brain icon" style="width: 85px; float: left; margin-right: 40px;" />

Let's get some fingers on the keyboard and explore an Elixir library.

Gibran is an early Elixir library that experimented with natural language processor. It can convert a string into a list of tokens using different strategies.

```elixir
str = "Tomorrow, and tomorrow, and tomorrow, Creeps in this petty pace from day to day"

Gibran.Tokeniser.tokenise(str)
|> IO.inspect(label: "tokens")

Gibran.Tokeniser.tokenise(str)
|> Gibran.Counter.uniq_tokens()
|> IO.inspect(label: "unqiue tokens")

Gibran.Tokeniser.tokenise(str, exclude: &(String.length(&1) < 5))
|> IO.inspect(label: "tokens > 10")

Gibran.Tokeniser.tokenise(str, exclude: &(String.length(&1) < 5))
|> Enum.uniq()
|> IO.inspect(label: "unique tokens > 10")

# idea for a little challenge; have them count the tokens in the first two 
# and add the uniq in the final? No need for a solution, but it could be hidden 
# in a markdown section

:ok
```

<hr style="background-color: #800080;height: 15.0px;" />

## Problems in Machine Learning

<img src="https://static.thenounproject.com/png/1038260-200.png" alt="Caution icon" style="width: 95px; float: left; margin-right: 50px;" />

It is easy to think that more data is better. More data generally leads to increased accuracy. It also leads to decreased performance in addition to difficulty in visualizing the data.

### Generalization

The goal of training a model is to make that model perform accurately on data it has never seen before. This is called Generalization. The generalization of a model to new data is what makes machine learning useful in solving everyday problems that require predictions or classification.

Say you train a model to classify images into two groups: "dogs" or "not dogs". If the dataset you used to train the model contains only two breeds of dogs it may perform very accurately. Will it generalize to a dataset containing more dog breeds? Or one with cats and wolves? Unlikely. In this case you might see the testing dataset with 90% accuracy. That accuracy is likely to drop to the 70s for the other dog breeds and below 40 for the mix of animals.

The problem in this example is a lack of data diversity. Let's look at two other problems we can run into with training data: overfitting and underfitting.

<!-- livebook:{"break_markdown":true} -->

![](images/fit.png)

<!-- livebook:{"break_markdown":true} -->

### Overfitting

Overfitting is when a model too closely matches, or fits, its training data. This means the model will not predict unseen data accurately, or not generalize. This can happen when a model trains for too long or when the model is too complex. In those cases, the model can start to learn from irrelevant information in the dataset and fit the training set too closely

Low error rates are good indicators of overfitting. In order to prevent this type of behavior, part of the training dataset is typically set aside as the *Test Set* to check for overfitting. Overfitting is indicated when the training data has a low error rate and the test data has a high error rate.

![](images/overfit.png)

<!-- livebook:{"break_markdown":true} -->

![](images/overfit.png)

<!-- livebook:{"break_markdown":true} -->

### Underfitting

Underfitting is when a model produces inaccurate prediction outcomes because it failed to catpure the complexity of the training data. It occurs when the model has not trained for enough time or the input variables are not significant enough to form a meaningful relationship between the input and output. Underfitting, like overfitting, generalizes poorly to unseen data.

![](images/underfit.png)

<!-- livebook:{"break_markdown":true} -->

![](images/underfit.png)

<!-- livebook:{"break_markdown":true} -->

[<span style="float: right; color: #800080; font-weight: bold; font-family: FreeMono, monospace">next ></span>](2_Supervised.livemd)
