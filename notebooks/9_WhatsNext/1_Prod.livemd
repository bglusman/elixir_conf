# What's Next? / Nx in Production

## Goal

What do think about before you put machine learning into your production environment.

<!-- livebook:{"break_markdown":true} -->

### Concerns

* Integration
* Performance
* Cost
* Versioning
* Workflow automation
* Monitor for model decay

<!-- livebook:{"break_markdown":true} -->

### Performance

Any machine learning models must integrate with your current systems. This brings up concerns around tech stack, third party app support, and data storage options.

Performance depends upon that data. The data you want to make predictions about must share features with the data used to train the model.

<!-- livebook:{"break_markdown":true} -->

```mermaid
flowchart LR
    mr(Model requirements) --> ld(Live data)
    ld --> dc(Data collection)
    dc --> dl(Data labeling)
    dl --> cl(Data cleaning) 
    cl --> m(Production model)
    m --> p(Predictions!)
    style ld fill:#000,stroke:#333,color:#019EFE,stroke-width:4px
    style mr fill:#000,stroke:#333,color:#fff,stroke-width:2px
    style dc fill:#808,stroke:#333,color:#fff,stroke-width:4px
    style cl fill:#808,stroke:#333,color:#fff,stroke-width:4px
    style dl fill:#808,stroke:#333,color:#fff,stroke-width:4px
    style m fill:#019EFE,stroke:#000,stroke-width:2px,color:#000
```

<!-- livebook:{"break_markdown":true} -->

#### Workflow

Developing an ML model includes evaluating its performance.

```mermaid
flowchart TB
    hd(Historical data)-->m(Model)
    m<-->me(Model evaluation)
    d-->p(Production)
    ld(Live data)-->p 
    p<-->pe(Production evaluation)
    m-->d(Deployment)
    style hd fill:#000,stroke:#333,color:#fff,stroke-width:4px
    style ld fill:#000,stroke:#333,color:#019EFE,stroke-width:4px
    style m fill:#808,stroke:#333,color:#fff,stroke-width:4px
    style me fill:#bbf,stroke:#808,stroke-width:2px,color:#000,stroke-dasharray: 5 5
    style d fill:#bbf,stroke:#000,stroke-width:2px,color:#000
    style p fill:#019EFE,stroke:#000,stroke-width:2px,color:#000
    style pe fill:#B7D7EB,stroke:#019EFE,stroke-width:2px,color:#000,stroke-dasharray: 5 5
```

<!-- livebook:{"break_markdown":true} -->

##### Evaluation

Models may require different evaluation at different points in the development cycle. During model evaluation you may evaluate on accuracy. Production evaluation may consider value of the data to customers. The distribution of the data may change over time. Detect distribution drift through continuous model monitoring.

<!-- livebook:{"break_markdown":true} -->

```mermaid
flowchart TB
    hd(Historical Data)-->tr(Train data)
    hd-->te(Test data)
    tr-->mt(Model training)
    hp(Hyperparameters)-->mt
    te-->m(Model)
    m-->me(Evaluation)
    mt-->tre(Evaluation)
    me-->hp
    tre-->hp
    style hd fill:#000,stroke:#333,color:#fff,stroke-width:4px
    style te fill:#000,stroke:#333,color:#fff,stroke-width:4px
    style tr fill:#000,stroke:#333,color:#fff,stroke-width:4px
    style hp fill:#019EFE,stroke:#000,stroke-width:2px,color:#000
    style mt fill:#019EFE,stroke:#000,stroke-width:2px,color:#000
    style m fill:#019EFE,stroke:#000,stroke-width:2px,color:#000
    style me stroke:#808,stroke-width:2px,color:#000,stroke-dasharray: 5 5
    style tre stroke:#808,stroke-width:2px,color:#000,stroke-dasharray: 5 5
```

<!-- livebook:{"break_markdown":true} -->

### Deployment

Large data sets and deep learning systems make it challenging to scale model training. Additionally, models need to be updated regularly as a result of continuous evaluation and improvement plus to correct distribution shifts. The manual steps of learning and deploying models can quickly become tedious and error prone.

The machine learning community is paying increasing attention to scalability through parallelization, which makes the recent boom in the Nx ecosystem timely.

<!-- livebook:{"break_markdown":true} -->

### Storage

If you will be using your own data to get predictions from your model, such as in the case of sentiment analysis of customer inquiries, you will need to thinking about:

* how to store the dataset
* how big it will be
* how to get it out for training
* how to get it out for predicting

### Conclusion

Given these concerns, it quickly becomes apparent that machine learning is part of a larger system. To maintain that system from development through deployment requires a holistic approach with an interdisciplinary team.

In this training we've focused on models. More than building accurate models and integrating them into a system, we have to plan for how to best collect data and what the best data to collect is. To move what you've learned into a production environment you need to address the concerns raised here to support rapid experimentation and improvement in production.

<!-- livebook:{"break_markdown":true} -->

[<span style="float: left; color: #800080; font-weight: bold; font-family: FreeMono, monospace">< previous chapter: Nx In Action</span>](../8_NxInAction/1_Intro.livemd)

[<span style="float: right; color: #800080; font-weight: bold; font-family: FreeMono, monospace">next ></span>](2_Future.livemd)
